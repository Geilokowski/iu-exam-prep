### Bruteforce

- Versuchen mit stumpfem ausprobieren die Lösung zu finden
- Dauert (meist) extrem lange
### Greedy

- In jedem Schritt wird die am besten erscheinende Wahl getroffen ohne sich um die langfristigen Auswirkungen zu kümmern
- Jeder Schritt wird lokal optimiert, in der Hoffnung, dass dies zu einer global optimalen Lösung führt.
- Greedy Algorthmen führen (genau wie andere Typen) nicht immer zur besten Lösung
### Rekursion

- Algorithmen die sich selbst aufrufen
- Dient zur Teilung der Aufgabe in kleine Teile
- Rekursion ist Leistungstechnisch teuer
### Backtracking

- Funktioniert nach dem trial and error Prinzip
- Versucht eine erreichte Teillösung zu einer Gesamtlösung auszubauen
- Wenn Absehbar ist, dass eine Teillösung nicht zur endgültigen Lösung führt werden die letzten Schritte zurückgenommen und alternative Wege getestet
- So ist sichergestellt, dass alle in Frage kommenden Lösungswege ausprobiert werden können
#### Backtracking - Beispiel

![](Pasted%20image%2020231212003201.png)

![](Pasted%20image%2020231212003221.png)

![](Pasted%20image%2020231212003239.png)
### Dynamic Programming

- Ein großes Problem wird in kleine Teilprobleme aufgeteilt
- Die Lösungen der Teilprobleme werden zwischengespeichert
- Wenn ein Teilproblem nochmal auftritt kann die gespeicherte Lösung wiederverwendet werden
#### Dynamic Programming - Beispiel

![](Pasted%20image%2020231212133040.png)

Hier ist folgendes zu erkennen:
- Im Rekursiven Lösungsansatz ist der Aufwand exponenziel da durch die Erhöhung von `n` um 1 immer doppelt so viele `fib` aufrufe ausgeführt werden müssen.
- In der Lösung per Dynamic Programming wird die letzte ausgerechnete Teillösung `f[i]` immer gespeichert, so kann bei der Erhöhung von `n` einfach darauf zugegriffen werden.
### Randomisierte Algorithmen
#### Monte Carlo

- Kann mit einer gewissen Wahrscheinlichkeit Fehler machen
- Die Unsicherheit liegt also in der Korrektheit des Ergebnisses
- Genauigkeit kann durch wiederholtes Ausführen verbessert werden
- Die Laufzeit ist in der Regel deterministisch und hängt nicht vom Ergebnis ab
#### Las Vegas

- Darf keine Fehler machen
- Die Laufzeit kann sich aber von Ausführung zu Ausführung stark unterscheiden
	- Das liegt daran, dass der Algorithmus zufällige Parameter nutzt
	- Wenn der Algorithmus feststellt das Ergebnis was er berechnet hat ist nicht korrekt startet er neu
	- Das macht er so lange bis er zu einem korrekten Ergebnis kommt
### Teile und Herrsche

- Im Grunde wird ein Problem wieder in Teilprobleme aufgeteilt
- Am Ende werden die lokalen Lösungen dann zu einer globalen zusammengeführt
- Beispiel ist mergesort, dabei wird die zu sortierende Liste aufgeteilt und dann in kleinen Teilen sortiert, am Ende werden die kleinen Listen dann wieder zusammengeführt.
