### Einleitung

- Werkzeug zur Analyse der Laufzeit von Algorithmen
- Betrachtet rekursive Algorithmen
- Wichtig für die Klausur
### Das Master-Theorem

Definition: ${\displaystyle T(n)=a\cdot T(\textstyle {\frac {n}{b}})+f(n)}$

Wobei: 
- $T(n)$: die Zeitkomplexität des Algorithmus für ein Problem der Größe $n$
- $a$ die Anzahl der Teilprobleme in jeder Stufe der Rekursion
- ${\frac {n}{b}}$ die Größe jedes Teilproblems (wobei $b > 1$)
- $f(n)$ die Kosten für das Teilen des Problems und das Zusammenführen der Ergebnisse

Es wird in drei Fälle unterschieden:
- **$f(n)$ ist polynomiell kleiner**: 
	- Wenn $f(n)\in {\mathcal {O}}\left(n^{{\log _{b}a-\varepsilon }}\right)$ für ein $\varepsilon > 0$ 
	- Dann ist $T(n)\in \Theta \left(n^{{\log _{b}a}}\right)$
- **$f(n)$ ist gleich**: 
	- Wenn $f(n)\in \Theta \left(n^{{\log _{b}a}}\right)$ 
	- Dann ist $T(n)\in \Theta \left(n^{{\log _{b}a}}\log(n)\right)$
- **$f(n)$ ist polynomiell größer**: 
	- Wenn $f(n)\in \Omega \left(n^{{\log _{b}a+\varepsilon }}\right)$ für ein $\varepsilon > 0$ 
	- Wenn eine Konstante $0 < c < 1$ existiert sodass gilt $af(\textstyle {\frac {n}{b}})\leq cf(n)$
	- Dann ist $T(n)\in \Theta (f(n))$
### Beispiele

- Anmerkung: Der dritte Fall wurde in den Folien nicht behandelt, ich gehe davon aus er kommt nicht ran.

$O(n) = \Omega{n \log_a}$